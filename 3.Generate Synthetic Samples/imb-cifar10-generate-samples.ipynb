{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0df230",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-11T07:01:04.059256Z",
     "iopub.status.busy": "2023-09-11T07:01:04.058410Z",
     "iopub.status.idle": "2023-09-11T07:01:04.103740Z",
     "shell.execute_reply": "2023-09-11T07:01:04.102340Z"
    },
    "papermill": {
     "duration": 0.053613,
     "end_time": "2023-09-11T07:01:04.106262",
     "exception": false,
     "start_time": "2023-09-11T07:01:04.052649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/imb-trn-cifar10/trn_lab_imb/trn_lab_imb\n",
      "/kaggle/input/imb-trn-cifar10/BTestset/trn_lab_b\n",
      "/kaggle/input/imb-trn-cifar10/BTestset/trn_img_b\n",
      "/kaggle/input/imb-trn-cifar10/AutoEncoder_v2/bst_dec.pth\n",
      "/kaggle/input/imb-trn-cifar10/AutoEncoder_v2/bst_enc.pth\n",
      "/kaggle/input/imb-trn-cifar10/SMOTEd_v2/trn_lab\n",
      "/kaggle/input/imb-trn-cifar10/SMOTEd_v2/trn_img\n",
      "/kaggle/input/imb-trn-cifar10/NewKmeanAE/NewKmeanAE/0_bst_enc.pth\n",
      "/kaggle/input/imb-trn-cifar10/NewKmeanAE/NewKmeanAE/0_bst_dec.pth\n",
      "/kaggle/input/imb-trn-cifar10/ImbTestset/trn_lab_imb\n",
      "/kaggle/input/imb-trn-cifar10/ImbTestset/trn_img_imb\n",
      "/kaggle/input/imb-trn-cifar10/SMOTEd_Original/trn_lab\n",
      "/kaggle/input/imb-trn-cifar10/SMOTEd_Original/trn_img\n",
      "/kaggle/input/imb-trn-cifar10/trn_img_imb/trn_img_imb\n",
      "/kaggle/input/imb-trn-cifar10/AutoDecoder_Original/0_bst_enc.pth\n",
      "/kaggle/input/imb-trn-cifar10/AutoDecoder_Original/0_bst_dec.pth\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3cfa395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T07:01:04.113287Z",
     "iopub.status.busy": "2023-09-11T07:01:04.113002Z",
     "iopub.status.idle": "2023-09-11T07:14:55.367231Z",
     "shell.execute_reply": "2023-09-11T07:14:55.366055Z"
    },
    "papermill": {
     "duration": 831.264058,
     "end_time": "2023-09-11T07:14:55.373103",
     "exception": false,
     "start_time": "2023-09-11T07:01:04.109045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0\n",
      "['/kaggle/input/imb-trn-cifar10/trn_img_imb/trn_img_imb']\n",
      "['/kaggle/input/imb-trn-cifar10/trn_lab_imb/trn_lab_imb']\n",
      "/kaggle/input/imb-trn-cifar10/NewKmeanAE/NewKmeanAE/0_bst_enc.pth\n",
      "/kaggle/input/imb-trn-cifar10/NewKmeanAE/NewKmeanAE/0_bst_dec.pth\n",
      "\n",
      "0\n",
      "/kaggle/input/imb-trn-cifar10/trn_img_imb/trn_img_imb\n",
      "/kaggle/input/imb-trn-cifar10/trn_lab_imb/trn_lab_imb\n",
      "train imgs before reshape  (10280, 3072)\n",
      "train labels  (10280,)\n",
      "decy  (10280,)\n",
      "Counter({0.0: 4500, 1.0: 2000, 2.0: 1000, 3.0: 800, 4.0: 600, 5.0: 500, 6.0: 400, 7.0: 250, 8.0: 150, 9.0: 80})\n",
      "train imgs after reshape  (10280, 3, 32, 32)\n",
      "(2000, 3, 32, 32)\n",
      "1.0\n",
      "torch.Size([2000, 600])\n",
      "(2500, 600)\n",
      "2500\n",
      "(2500,)\n",
      "(2500, 3, 32, 32)\n",
      "(2500, 3, 32, 32)\n",
      "(1000, 3, 32, 32)\n",
      "2.0\n",
      "torch.Size([1000, 600])\n",
      "(3500, 600)\n",
      "3500\n",
      "(3500,)\n",
      "(3500, 3, 32, 32)\n",
      "(3500, 3, 32, 32)\n",
      "(800, 3, 32, 32)\n",
      "3.0\n",
      "torch.Size([800, 600])\n",
      "(3700, 600)\n",
      "3700\n",
      "(3700,)\n",
      "(3700, 3, 32, 32)\n",
      "(3700, 3, 32, 32)\n",
      "(600, 3, 32, 32)\n",
      "4.0\n",
      "torch.Size([600, 600])\n",
      "(3900, 600)\n",
      "3900\n",
      "(3900,)\n",
      "(3900, 3, 32, 32)\n",
      "(3900, 3, 32, 32)\n",
      "(500, 3, 32, 32)\n",
      "5.0\n",
      "torch.Size([500, 600])\n",
      "(4000, 600)\n",
      "4000\n",
      "(4000,)\n",
      "(4000, 3, 32, 32)\n",
      "(4000, 3, 32, 32)\n",
      "(400, 3, 32, 32)\n",
      "6.0\n",
      "torch.Size([400, 600])\n",
      "(4100, 600)\n",
      "4100\n",
      "(4100,)\n",
      "(4100, 3, 32, 32)\n",
      "(4100, 3, 32, 32)\n",
      "(250, 3, 32, 32)\n",
      "7.0\n",
      "torch.Size([250, 600])\n",
      "(4250, 600)\n",
      "4250\n",
      "(4250,)\n",
      "(4250, 3, 32, 32)\n",
      "(4250, 3, 32, 32)\n",
      "(150, 3, 32, 32)\n",
      "8.0\n",
      "torch.Size([150, 600])\n",
      "(4350, 600)\n",
      "4350\n",
      "(4350,)\n",
      "(4350, 3, 32, 32)\n",
      "(4350, 3, 32, 32)\n",
      "(80, 3, 32, 32)\n",
      "9.0\n",
      "torch.Size([80, 600])\n",
      "(4420, 600)\n",
      "4420\n",
      "(4420,)\n",
      "(4420, 3, 32, 32)\n",
      "(4420, 3, 32, 32)\n",
      "(34720, 3, 32, 32)\n",
      "(34720,)\n",
      "(34720, 3072)\n",
      "decx1  (10280, 3072)\n",
      "(45000, 3072)\n",
      "(45000,)\n",
      "\n",
      "final time(min): 13.81\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import os\n",
    "print(torch.version.cuda) #10.1\n",
    "import time\n",
    "t0 = time.time()\n",
    "##############################################################################\n",
    "\"\"\"args for models\"\"\"\n",
    "\n",
    "args = {}\n",
    "args['dim_h'] = 64          # factor controlling size of hidden layers\n",
    "args['n_channel'] = 3       # number of channels in the input data \n",
    "\n",
    "args['n_z'] = 600 #600     # number of dimensions in latent space. \n",
    "\n",
    "args['sigma'] = 1.0        # variance in n_z\n",
    "args['lambda'] = 0.01      # hyper param for weight of discriminator loss\n",
    "args['lr'] = 0.0002        # learning rate for Adam optimizer .000\n",
    "args['epochs'] = 500 #50         # how many epochs to run for\n",
    "args['batch_size'] = 100   # batch size for SGD\n",
    "args['save'] = True        # save weights at each epoch of training if True\n",
    "args['train'] = True       # train networks if True, else load networks from\n",
    "\n",
    "args['dataset'] = 'cifar10' #'fmnist' # specify which dataset to use\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "## create encoder model and decoder model\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.n_channel = args['n_channel']\n",
    "        self.dim_h = args['dim_h']\n",
    "        self.n_z = args['n_z']\n",
    "        \n",
    "        # convolutional filters, work excellent with image data\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.n_channel, self.dim_h, 4, 2, 1, bias=False),\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.dim_h * 2),\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.dim_h * 4),\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            \n",
    "            #nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 1, bias=False),\n",
    "            \n",
    "            #3d and 32 by 32\n",
    "            nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 1, 0, bias=False),\n",
    "            \n",
    "            nn.BatchNorm2d(self.dim_h * 8), # 40 X 8 = 320\n",
    "            #nn.ReLU(True),\n",
    "            nn.LeakyReLU(0.2, inplace=True) )#,\n",
    "            #nn.Conv2d(self.dim_h * 8, 1, 2, 1, 0, bias=False))\n",
    "            #nn.Conv2d(self.dim_h * 8, 1, 4, 1, 0, bias=False))\n",
    "        # final layer is fully connected\n",
    "        self.fc = nn.Linear(self.dim_h * (2 ** 3), self.n_z)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #print('enc')\n",
    "        #print('input ',x.size()) #torch.Size([100, 3,32,32])\n",
    "        x = self.conv(x)\n",
    "        #print('aft conv ',x.size()) #torch.Size([100, 320, 2, 2]) with \n",
    "        #nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 1, bias=False),\n",
    "        #vs torch.Size([128, 320, 1, 1])\n",
    "        #aft conv  torch.Size([100, 320, 1, 1]) with \n",
    "        #nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 1, 0, bias=False),\n",
    "        x = x.squeeze()\n",
    "        #print('aft squeeze ',x.size()) #torch.Size([128, 320])\n",
    "        #aft squeeze  torch.Size([100, 320])\n",
    "        x = self.fc(x)\n",
    "        #print('out ',x.size()) #torch.Size([128, 20])\n",
    "        #out  torch.Size([100, 300])\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.n_channel = args['n_channel']\n",
    "        self.dim_h = args['dim_h']\n",
    "        self.n_z = args['n_z']\n",
    "\n",
    "        # first layer is fully connected\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.n_z, self.dim_h * 8 * 9 * 9),\n",
    "            nn.ReLU())\n",
    "\n",
    "        # deconvolutional filters, essentially inverse of convolutional filters\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4),\n",
    "            nn.BatchNorm2d(self.dim_h * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4),\n",
    "            nn.BatchNorm2d(self.dim_h * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(self.dim_h * 2, 3, 4, stride=2),\n",
    "            #nn.Sigmoid()\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print('dec')\n",
    "        #print('input ',x.size())\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, self.dim_h * 8, 9, 9)\n",
    "        x = self.deconv(x)\n",
    "        return x\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "def biased_get_class1(c):\n",
    "    \n",
    "    xbeg = dec_x[dec_y == c]\n",
    "    ybeg = dec_y[dec_y == c]\n",
    "    \n",
    "    return xbeg, ybeg\n",
    "    #return xclass, yclass\n",
    "\n",
    "\n",
    "def G_SM1(X, y,n_to_sample,cl):\n",
    "\n",
    "    \n",
    "    # fitting the model\n",
    "    n_neigh = 5 + 1\n",
    "    nn = NearestNeighbors(n_neighbors=n_neigh, n_jobs=1)\n",
    "    nn.fit(X)\n",
    "    dist, ind = nn.kneighbors(X)\n",
    "\n",
    "    # generating samples\n",
    "    base_indices = np.random.choice(list(range(len(X))),n_to_sample)\n",
    "    neighbor_indices = np.random.choice(list(range(1, n_neigh)),n_to_sample)\n",
    "\n",
    "    X_base = X[base_indices]\n",
    "    X_neighbor = X[ind[base_indices, neighbor_indices]]\n",
    "\n",
    "    samples = X_base + np.multiply(np.random.rand(n_to_sample,1),\n",
    "            X_neighbor - X_base)\n",
    "\n",
    "    #use 10 as label because 0 to 9 real classes and 1 fake/smoted = 10\n",
    "    return samples, [cl]*n_to_sample\n",
    "\n",
    "#############################################################################\n",
    "np.printoptions(precision=5,suppress=True)\n",
    "\n",
    "dtrnimg = '/kaggle/input/imb-trn-cifar10/trn_img_imb'\n",
    "dtrnlab = '/kaggle/input/imb-trn-cifar10/trn_lab_imb'\n",
    "\n",
    "ids = os.listdir(dtrnimg)\n",
    "idtri_f = [os.path.join(dtrnimg, image_id) for image_id in ids]\n",
    "idtri_f.sort()\n",
    "print(idtri_f)\n",
    "\n",
    "ids = os.listdir(dtrnlab)\n",
    "idtrl_f = [os.path.join(dtrnlab, image_id) for image_id in ids]\n",
    "idtrl_f.sort()\n",
    "print(idtrl_f)\n",
    "\n",
    "#path on the computer where the models are stored\n",
    "modpth = '/kaggle/input/imb-trn-cifar10/NewKmeanAE/NewKmeanAE'\n",
    "\n",
    "encf = []\n",
    "decf = []\n",
    "#for p in range(5):\n",
    "for p in range(1):\n",
    "    enc = modpth + '/' + str(p) + '_bst_enc.pth'\n",
    "    #enc = '/kaggle/input/imb-trn-cifar10/AutoEncoder_v2/bst_enc.pth'\n",
    "    dec = modpth + '/' + str(p) + '_bst_dec.pth'\n",
    "    #dec = '/kaggle/input/imb-trn-cifar10/AutoEncoder_v2/bst_dec.pth'\n",
    "    encf.append(enc)\n",
    "    decf.append(dec)\n",
    "    print(enc)\n",
    "    print(dec)\n",
    "    print()\n",
    "\n",
    "#for m in range(5):\n",
    "for m in range(1):\n",
    "    print(m)\n",
    "    trnimgfile = idtri_f[m]\n",
    "    trnlabfile = idtrl_f[m]\n",
    "    print(trnimgfile)\n",
    "    print(trnlabfile)\n",
    "    dec_x = np.loadtxt(trnimgfile) \n",
    "    dec_y = np.loadtxt(trnlabfile)\n",
    "\n",
    "    print('train imgs before reshape ',dec_x.shape) #(44993, 3072) 45500, 3072)\n",
    "    print('train labels ',dec_y.shape) #(44993,) (45500,)\n",
    "\n",
    "    dec_x = dec_x.reshape(dec_x.shape[0],3,32,32)\n",
    "\n",
    "    print('decy ',dec_y.shape)\n",
    "    print(collections.Counter(dec_y))\n",
    "    \n",
    "    print('train imgs after reshape ',dec_x.shape) #(45000,3,32,32)\n",
    "\n",
    "    classes = ('0', '1', '2', '3', '4',\n",
    "           '5', '6', '7', '8', '9')\n",
    "    \n",
    "    #generate some images \n",
    "    train_on_gpu = torch.cuda.is_available()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    path_enc = encf[m]\n",
    "    path_dec = decf[m]\n",
    "\n",
    "    encoder = Encoder(args)\n",
    "    encoder.load_state_dict(torch.load(path_enc), strict=False)\n",
    "    encoder = encoder.to(device)\n",
    "\n",
    "    decoder = Decoder(args)\n",
    "    decoder.load_state_dict(torch.load(path_dec), strict=False)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    imbal = [4500, 2000, 1000, 800, 600, 500, 400, 250, 150, 80]\n",
    "    #imbal = [4000, 2000, 1000, 750, 500, 350, 200, 100, 60, 40]\n",
    "\n",
    "    resx = []\n",
    "    resy = []\n",
    "\n",
    "    for i in range(1,10):\n",
    "        xclass, yclass = biased_get_class1(i)\n",
    "        print(xclass.shape) #(500, 3, 32, 32)\n",
    "        print(yclass[0]) #(500,)\n",
    "            \n",
    "        #encode xclass to feature space\n",
    "        xclass = torch.Tensor(xclass)\n",
    "        xclass = xclass.to(device)\n",
    "        xclass = encoder(xclass)\n",
    "        print(xclass.shape) #torch.Size([500, 600])\n",
    "            \n",
    "        xclass = xclass.detach().cpu().numpy()\n",
    "        n = imbal[0] - imbal[i]\n",
    "        xsamp, ysamp = G_SM1(xclass,yclass,n,i)\n",
    "        print(xsamp.shape) #(4500, 600)\n",
    "        print(len(ysamp)) #4500\n",
    "        ysamp = np.array(ysamp)\n",
    "        print(ysamp.shape) #4500   \n",
    "    \n",
    "        \"\"\"to generate samples for resnet\"\"\"   \n",
    "        xsamp = torch.Tensor(xsamp)\n",
    "        xsamp = xsamp.to(device)\n",
    "        #xsamp = xsamp.view(xsamp.size()[0], xsamp.size()[1], 1, 1)\n",
    "        #print(xsamp.size()) #torch.Size([10, 600, 1, 1])\n",
    "        ximg = decoder(xsamp)\n",
    "\n",
    "        ximn = ximg.detach().cpu().numpy()\n",
    "        print(ximn.shape) #(4500, 3, 32, 32)\n",
    "        #ximn = np.expand_dims(ximn,axis=1)\n",
    "        print(ximn.shape) #(4500, 3, 32, 32)\n",
    "        resx.append(ximn)\n",
    "        resy.append(ysamp)\n",
    "        #print('resx ',resx.shape)\n",
    "        #print('resy ',resy.shape)\n",
    "        #print()\n",
    "    \n",
    "    resx1 = np.vstack(resx)\n",
    "    resy1 = np.hstack(resy)\n",
    "    #print(resx1.shape) #(34720, 3, 32, 32)\n",
    "    #resx1 = np.squeeze(resx1)\n",
    "    print(resx1.shape) #(34720, 3, 32, 32)\n",
    "    print(resy1.shape) #(34720,)\n",
    "\n",
    "    resx1 = resx1.reshape(resx1.shape[0],-1)\n",
    "    print(resx1.shape) #(34720, 3072)\n",
    "    \n",
    "    dec_x1 = dec_x.reshape(dec_x.shape[0],-1)\n",
    "    print('decx1 ',dec_x1.shape)\n",
    "    combx = np.vstack((resx1,dec_x1))\n",
    "    comby = np.hstack((resy1,dec_y))\n",
    "\n",
    "    print(combx.shape) #(45000, 3, 32, 32)\n",
    "    print(comby.shape) #(45000,)\n",
    "\n",
    "    #ifile = '.../MNIST/trn_img_f/' + \\\n",
    "        #str(m) + '_trn_img.txt'\n",
    "    ifile = '/kaggle/working/' + str(m) +'_trn_img.gz'\n",
    "    np.savetxt(ifile, combx)\n",
    "    \n",
    "    #lfile = '.../MNIST/trn_lab_f/' + \\\n",
    "        #str(m) + '_trn_lab.txt'\n",
    "    lfile = '/kaggle/working/' + str(m) + '_trn_lab.gz'\n",
    "    np.savetxt(lfile,comby) \n",
    "    print()\n",
    "\n",
    "t1 = time.time()\n",
    "print('final time(min): {:.2f}'.format((t1 - t0)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77596980",
   "metadata": {
    "papermill": {
     "duration": 0.003397,
     "end_time": "2023-09-11T07:14:55.380183",
     "exception": false,
     "start_time": "2023-09-11T07:14:55.376786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a href=\"/kaggle/working/trn_img.gz\"> Download File </a>"
   ]
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 842.229152,
   "end_time": "2023-09-11T07:14:56.810823",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-11T07:00:54.581671",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
